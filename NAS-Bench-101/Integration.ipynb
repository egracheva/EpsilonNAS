{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight ablations\n",
    "\n",
    "In this ablation study we verify how much does the performance of epsilon metric change depending on the chosen weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 18:03:07.409761: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/extras/CUPTI/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/extras/CUPTI/lib64\n",
      "2022-09-29 18:03:07.409882: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/extras/CUPTI/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/extras/CUPTI/lib64\n",
      "2022-09-29 18:03:07.409894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from tqdm import trange\n",
    "from dotmap import DotMap\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import nasspace\n",
    "from datasets import data\n",
    "from epsilon_utils import prepare_seed, compute_stats, plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = DotMap()\n",
    "args.data_loc = '../cifardata'\n",
    "args.api_loc = './nasbench_only108.tfrecord'\n",
    "args.save_loc = './results'\n",
    "args.score = 'hook_logdet'\n",
    "args.nasspace = 'nasbench101'\n",
    "args.batch_size=256\n",
    "args.repeat=1\n",
    "args.sigma=0.05\n",
    "args.GPU='3'\n",
    "args.seed=1\n",
    "args.init=''\n",
    "args.dataset='cifar10'\n",
    "args.maxofn=1\n",
    "args.n_samples=100\n",
    "args.n_runs=5\n",
    "args.stem_out_channels = 128\n",
    "args.num_stacks = 3\n",
    "args.num_modules_per_stack = 3\n",
    "args.num_labels = 1\n",
    "args.augtype='none'\n",
    "args.trainval=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from file... This may take a few minutes...\n",
      "WARNING:tensorflow:From /home/gracheva/Work/NAS/NAS-Bench-101/nasbench/api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "Loaded dataset in 73 seconds\n"
     ]
    }
   ],
   "source": [
    "# savedataset = args.dataset\n",
    "# dataset = 'fake' if 'fake' in savedataset else savedataset\n",
    "# savedataset = savedataset.replace('fake', '')\n",
    "# if savedataset == 'cifar10':\n",
    "#     savedataset = savedataset + '-valid'\n",
    "# searchspace = nasspace.get_search_space(args)\n",
    "# if 'valid' in savedataset:\n",
    "#     savedataset = savedataset.replace('-valid', '')\n",
    "    \n",
    "# if args.dataset == 'cifar10':\n",
    "#     acc_type = 'ori-test'\n",
    "#     val_acc_type = 'x-valid'\n",
    "# else:\n",
    "#     acc_type = 'x-test'\n",
    "#     val_acc_type = 'x-valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "synflow_proxy=[]\n",
    "save_dir = '/home/gracheva/Work/NAS/NAS-Bench-101/release_results/NAS-Bench-101/CIFAR10/WEIGHT_0.0001_10/BS_256'\n",
    "\n",
    "f = open('{}/Data'.format(save_dir),'rb')\n",
    "while(1):\n",
    "    try:\n",
    "        d = pickle.load(f)\n",
    "        nparams = d['nparams']\n",
    "        synflow_proxy = d['score']\n",
    "\n",
    "    except EOFError:\n",
    "        break\n",
    "f.close()\n",
    "\n",
    "# Treat NaNs\n",
    "synflow_proxy = np.array(synflow_proxy)\n",
    "synflow_proxy[np.isnan(synflow_proxy)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11873/1162230713.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0midx_to_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearchspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0midx_to_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_spec_from_arch_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "#dicts to map from index to spec or spec to index\n",
    "#spec is the model description within NAS, in our case we use an encoding [5, 5, 5, 5, 5, 5]\n",
    "#this is a length-6 vector, with each entry having a value between 0-4 \n",
    "#this is sufficient to describe any NAS-Bench-201 cell\n",
    "\n",
    "_opname_to_index = {\n",
    "    'none': 0,\n",
    "    'skip_connect': 1,\n",
    "    'nor_conv_1x1': 2,\n",
    "    'nor_conv_3x3': 3,\n",
    "    'avg_pool_3x3': 4\n",
    "}\n",
    "\n",
    "def get_spec_from_arch_str(arch_str):\n",
    "    print(arch_str)\n",
    "    nodes = arch_str.split('+')\n",
    "    nodes = [node[1:-1].split('|') for node in nodes]\n",
    "    nodes = [[op_and_input.split('~')[0]  for op_and_input in node] for node in nodes]\n",
    "\n",
    "    spec = [_opname_to_index[op] for node in nodes for op in node]\n",
    "    return spec\n",
    "\n",
    "idx_to_spec = {}\n",
    "for i, arch_str in enumerate(searchspace.mutate_arch):\n",
    "    idx_to_spec[i] = get_spec_from_arch_str(arch_str)\n",
    "\n",
    "spec_to_idx = {}\n",
    "for idx,spec in idx_to_spec.items():\n",
    "    spec_to_idx[str(spec)] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "def random_spec():\n",
    "    return random.choice(list(idx_to_spec.values()))\n",
    "\n",
    "def mutate_spec(old_spec):\n",
    "    idx_to_change = random.randrange(len(old_spec))\n",
    "    entry_to_change = old_spec[idx_to_change]\n",
    "    possible_entries = [x for x in range(5) if x != entry_to_change]\n",
    "    new_entry = random.choice(possible_entries)\n",
    "    new_spec = copy.copy(old_spec)\n",
    "    new_spec[idx_to_change] = new_entry\n",
    "    return new_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_combination(iterable, sample_size):\n",
    "    pool = tuple(iterable)\n",
    "    n = len(pool)\n",
    "    indices = sorted(random.sample(range(n), sample_size))\n",
    "    return tuple(pool[i] for i in indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution_search(max_trained_models=1000, \n",
    "                         pool_size=64, \n",
    "                         tournament_size=10, \n",
    "                         zero_cost_warmup=0, \n",
    "                         zero_cost_move=False):\n",
    "    \n",
    "    best_valids, best_tests = [0.0], [0.0]\n",
    "    pool = []   # (validation, spec) tuples\n",
    "    num_trained_models = 0\n",
    "\n",
    "    # fill the initial pool\n",
    "    if zero_cost_warmup > 0:\n",
    "        zero_cost_pool = []\n",
    "        for _ in range(zero_cost_warmup):\n",
    "            spec = random_spec()\n",
    "            spec_idx = spec_to_idx[str(spec)]\n",
    "            zero_cost_pool.append((synflow_proxy[spec_idx], spec))\n",
    "            zero_cost_pool = sorted(zero_cost_pool, key=lambda i:i[0], reverse=True)\n",
    "    for i in range(pool_size):\n",
    "        if zero_cost_warmup > 0:\n",
    "            spec = zero_cost_pool[i][1]\n",
    "        else:\n",
    "            spec = random_spec()\n",
    "#         info = api.get_more_info(spec_to_idx[str(spec)], 'ImageNet16-120', iepoch=None, hp='200', is_random=False)\n",
    "        info = api.get_more_info(spec_to_idx[str(spec)], 'cifar100', iepoch=None, hp='200', is_random=False)\n",
    "\n",
    "        num_trained_models += 1\n",
    "        pool.append((info['valid-accuracy'], spec))\n",
    "\n",
    "        if info['valid-accuracy'] > best_valids[-1]:\n",
    "            best_valids.append(info['valid-accuracy'])\n",
    "        else:\n",
    "            best_valids.append(best_valids[-1])\n",
    "            \n",
    "        if info['test-accuracy'] > best_tests[-1]:\n",
    "            best_tests.append(info['test-accuracy'])\n",
    "        else:\n",
    "            best_tests.append(best_tests[-1])\n",
    "\n",
    "    # After the pool is seeded, proceed with evolving the population.\n",
    "    while(1):\n",
    "        if zero_cost_move:\n",
    "            parent = sorted(pool, key=lambda i:i[0])[-1][1]\n",
    "        else:\n",
    "            parent = random_combination(pool, 1)[0][1]\n",
    "        \n",
    "        child = mutate_spec(parent)\n",
    "\n",
    "        info = api.get_more_info(spec_to_idx[str(child)], 'cifar100', iepoch=None, hp='200', is_random=False)\n",
    "        num_trained_models += 1\n",
    "\n",
    "        # kill the oldest individual in the population.\n",
    "        if zero_cost_move:\n",
    "            pool.append((synflow_proxy[spec_to_idx[str(child)]], child))\n",
    "        else:\n",
    "            pool.append((info['valid-accuracy'], child))\n",
    "        pool.pop(0)\n",
    "\n",
    "        if info['valid-accuracy'] > best_valids[-1]:\n",
    "            best_valids.append(info['valid-accuracy'])\n",
    "        else:\n",
    "            best_valids.append(best_valids[-1])\n",
    "            \n",
    "        if info['test-accuracy'] > best_tests[-1]:\n",
    "            best_tests.append(info['test-accuracy'])\n",
    "        else:\n",
    "            best_tests.append(best_tests[-1])\n",
    "\n",
    "        if num_trained_models >= max_trained_models:\n",
    "            break\n",
    "    best_tests.pop(0)\n",
    "    best_valids.pop(0)\n",
    "    return best_valids, best_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution_search(max_trained_models=1000, \n",
    "                         pool_size=64, \n",
    "                         tournament_size=10, \n",
    "                         zero_cost_warmup=0, \n",
    "                         zero_cost_move=False):\n",
    "    \n",
    "    best_valids, best_tests = [0.0], [0.0]\n",
    "    pool = []   # (validation, spec) tuples\n",
    "    num_trained_models = 0\n",
    "\n",
    "    # fill the initial pool\n",
    "    if zero_cost_warmup > 0:\n",
    "        zero_cost_pool = []\n",
    "        for _ in range(zero_cost_warmup):\n",
    "            spec = random_spec()\n",
    "            spec_idx = spec_to_idx[str(spec)]\n",
    "            zero_cost_pool.append((synflow_proxy[spec_idx], spec))\n",
    "            zero_cost_pool = sorted(zero_cost_pool, key=lambda i:i[0], reverse=True)\n",
    "    for i in range(pool_size):\n",
    "        if zero_cost_warmup > 0:\n",
    "            spec = zero_cost_pool[i][1]\n",
    "        else:\n",
    "            spec = random_spec()\n",
    "#         info = api.get_more_info(spec_to_idx[str(spec)], 'ImageNet16-120', iepoch=None, hp='200', is_random=False)\n",
    "        info = api.get_more_info(spec_to_idx[str(spec)], 'cifar100', iepoch=None, hp='200', is_random=False)\n",
    "\n",
    "        num_trained_models += 1\n",
    "        pool.append((info['valid-accuracy'], spec))\n",
    "\n",
    "        if info['valid-accuracy'] > best_valids[-1]:\n",
    "            best_valids.append(info['valid-accuracy'])\n",
    "        else:\n",
    "            best_valids.append(best_valids[-1])\n",
    "            \n",
    "        if info['test-accuracy'] > best_tests[-1]:\n",
    "            best_tests.append(info['test-accuracy'])\n",
    "        else:\n",
    "            best_tests.append(best_tests[-1])\n",
    "\n",
    "    # After the pool is seeded, proceed with evolving the population.\n",
    "    while(1):\n",
    "        if zero_cost_move:\n",
    "            parent = sorted(pool, key=lambda i:i[0])[-1][1]\n",
    "        else:\n",
    "            parent = random_combination(pool, 1)[0][1]\n",
    "        \n",
    "        child = mutate_spec(parent)\n",
    "\n",
    "        info = api.get_more_info(spec_to_idx[str(child)], 'cifar100', iepoch=None, hp='200', is_random=False)\n",
    "        num_trained_models += 1\n",
    "\n",
    "        # kill the oldest individual in the population.\n",
    "        if zero_cost_move:\n",
    "            pool.append((synflow_proxy[spec_to_idx[str(child)]], child))\n",
    "        else:\n",
    "            pool.append((info['valid-accuracy'], child))\n",
    "        pool.pop(0)\n",
    "\n",
    "        if info['valid-accuracy'] > best_valids[-1]:\n",
    "            best_valids.append(info['valid-accuracy'])\n",
    "        else:\n",
    "            best_valids.append(best_valids[-1])\n",
    "            \n",
    "        if info['test-accuracy'] > best_tests[-1]:\n",
    "            best_tests.append(info['test-accuracy'])\n",
    "        else:\n",
    "            best_tests.append(best_tests[-1])\n",
    "\n",
    "        if num_trained_models >= max_trained_models:\n",
    "            break\n",
    "    best_tests.pop(0)\n",
    "    best_valids.pop(0)\n",
    "    return best_valids, best_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(max_trained_models=1000, \n",
    "                      zero_cost_warmup=0):\n",
    "    \n",
    "    best_valids, best_tests = [0.0], [0.0]\n",
    "    pool = []   # (validation, spec) tuples\n",
    "    num_trained_models = 0\n",
    "\n",
    "    # fill the initial pool\n",
    "    if zero_cost_warmup > 0:\n",
    "        zero_cost_pool = []\n",
    "        for _ in range(zero_cost_warmup):\n",
    "            spec = random_spec()\n",
    "            spec_idx = spec_to_idx[str(spec)]\n",
    "            zero_cost_pool.append((synflow_proxy[spec_idx], spec))\n",
    "            zero_cost_pool = sorted(zero_cost_pool, key=lambda i:i[0], reverse=True)\n",
    "    for i in range(max_trained_models):\n",
    "        if i < zero_cost_warmup:\n",
    "            spec = zero_cost_pool[i][1]\n",
    "        else:\n",
    "            spec = random_spec()\n",
    "        info = api.get_more_info(spec_to_idx[str(spec)], 'cifar100', iepoch=None, hp='200', is_random=False)\n",
    "\n",
    "        if info['valid-accuracy'] > best_valids[-1]:\n",
    "            best_valids.append(info['valid-accuracy'])\n",
    "        else:\n",
    "            best_valids.append(best_valids[-1])\n",
    "            \n",
    "        if info['test-accuracy'] > best_tests[-1]:\n",
    "            best_tests.append(info['test-accuracy'])\n",
    "        else:\n",
    "            best_tests.append(best_tests[-1])\n",
    "            \n",
    "    best_tests.pop(0)\n",
    "    best_valids.pop(0)\n",
    "    return best_valids, best_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "random.seed = 21\n",
    "num_rounds = 100\n",
    "length = 300\n",
    "ae, ae_warmup, ae_move, ae_warmup_move, rand, rand_warmup = [], [], [], [], [], []\n",
    "for _ in tqdm(range(num_rounds)):\n",
    "    ae_best_valids, ae_best_tests = run_evolution_search(max_trained_models=length)\n",
    "    ae.append(ae_best_tests)\n",
    "    ae_warmup_best_valids, ae_warmup_best_tests = run_evolution_search(max_trained_models=length, zero_cost_warmup=3000)\n",
    "    ae_warmup.append(ae_warmup_best_tests)\n",
    "    ae_move_best_valids, ae_move_best_tests = run_evolution_search(max_trained_models=length, zero_cost_move=True)\n",
    "    ae_move.append(ae_move_best_tests)\n",
    "    ae_warmup_move_best_valids, ae_warmup_move_best_tests = run_evolution_search(max_trained_models=length, zero_cost_warmup=3000, zero_cost_move=True)\n",
    "    ae_warmup_move.append(ae_warmup_move_best_tests)\n",
    "    rand_best_valids, rand_best_tests = run_random_search(max_trained_models=length)\n",
    "    rand.append(rand_best_tests)\n",
    "    rand_warmup_best_valids, rand_warmup_best_tests = run_random_search(max_trained_models=length, zero_cost_warmup=3000)\n",
    "    rand_warmup.append(rand_warmup_best_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_experiment(exp_list, title, filename):\n",
    "    fig = plt.figure(figsize=(6,4.5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    def plot_exp(exp, label):\n",
    "        exp = np.array(exp) \n",
    "        q_75 = np.quantile(exp, .75, axis=0)\n",
    "        q_25 = np.quantile(exp, .25, axis=0)\n",
    "        median = np.median(exp, axis=0)\n",
    "        ax.plot(median, label=label)\n",
    "        ax.fill_between(range(len(q_25)), q_25, q_75, alpha=0.1)\n",
    "    for exp,ename in exp_list:\n",
    "        plot_exp(exp, ename)\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                 ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(16)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.xlabel('Trained Models', fontsize = 22)\n",
    "    plt.ylabel('Test Accuracy', fontsize = 22)\n",
    "    plt.ylim(70,73.6) #89,92   44,47    70,73.6\n",
    "    plt.legend(fontsize = 16)\n",
    "    plt.title(title, fontsize = 22)\n",
    "    plt.savefig(filename,\n",
    "                bbox_inches='tight', \n",
    "                dpi=300,\n",
    "                format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/gracheva/Work/NAS/NAS-Bench-101/release_results/NAS-Bench-101/RE'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "filename=save_dir + 'Evolution_Len300_Rounds100_Move_RE.pdf'\n",
    "plot_experiment([(ae,'AE'), (ae_warmup,'AE + warmup'), (ae_move,'AE + move'), (ae_warmup_move, 'AE + warmup + move')], 'Aging Evolution Search', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = save_dir+\"_RS3000+RS_100it.pdf\"\n",
    "plot_experiment([(rand,'RAND'), (rand_warmup,'RAND + warmup (3000)')], 'Random Search', filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
